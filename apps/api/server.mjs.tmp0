import express from "express";
import cors from "cors";
import multer from "multer";
import fs from "node:fs";
import os from "node:os";
import path from "node:path";
import memoryRoutes from './routes/memory.mjs';
import { addTurn, recentTurns, getKV } from './lib/memory.mjs';

const app  = express();
const PORT = process.env.PORT || 3000;

app.use(express.json({ limit: "25mb" }));
app.use(cors({ origin: true }));

// ---- uploads ----
const UPLOAD_DIR = process.env.HENRY_UPLOAD_DIR || path.join(os.homedir(),"henry/data/uploads");
fs.mkdirSync(UPLOAD_DIR, { recursive: true });
app.use("/uploads", express.static(UPLOAD_DIR));
const storage = multer.diskStorage({
  destination: (_req,_file,cb) => cb(null, UPLOAD_DIR),
  filename: (_req, file, cb) => {
    const safe = String(file?.originalname || "file").replace(/[^a-zA-Z0-9._-]/g, "_");
    cb(null, `${Date.now()}-${safe}`);
  }
});
const upload = multer({ storage });

// ---- helpers ----
const getKey     = req => (req.get("x-api-key") || process.env.OPENAI_API_KEY || "").trim();
const getProject = req => (req.get("x-openai-project") || process.env.OPENAI_PROJECT_ID || "").trim();
const getOrg     = req => (req.get("x-openai-org")     || process.env.OPENAI_ORG_ID     || "").trim();
const lastUser   = msgs => Array.isArray(msgs) ? (msgs.slice().reverse().find(m=>m?.role==="user")?.content||"") : "";

function localPlan(text){
  const t = (text||"your task").slice(0,200);
  return [
    `Here’s a quick plan for ${t}:`,
    "1) Define what \"done\" means + constraints.",
    "2) Gather inputs (files/links/examples).",
    "3) Do the smallest test, review, iterate.",
    "",
    "Attach a file or say \"make a checklist\" to proceed."
  ].join("\n");
}

// ---- health ----
app.get("/health", (_req,res)=>res.json({ ok:true, service:"henry-api", ts:Date.now() }));
app.get("/ping",   (_req,res)=>res.json({ ok:true }));

// ---- upload ----
app.post(["/upload","/files/upload"], upload.single("file"), (req,res)=>{
  if (!req.file) return res.status(400).json({ ok:false, error:"no_file" });
  const url = "/uploads/" + encodeURIComponent(req.file.filename);
  res.json({ ok:true, file:{
    originalName: req.file.originalname,
    savedName: req.file.filename,
    size: req.file.size,
    mime: req.file.mimetype,
    url
  }});
});

// ---- chat: OpenAI-first, fallback to local plan ----
app.post("/chat", async (req,res)=>{
  try{
    const messages = Array.isArray(req.body?.messages) ? req.body.messages
                   : [{ role:"user", content: String(req.body?.text||req.body?.hi||"hello") }];

    const key = getKey(req);
    if (key){
      const headers = { "Authorization": `Bearer ${key}`, "Content-Type":"application/json" };
      const org  = getOrg(req);     if (org)  headers["OpenAI-Organization"] = org;
      const proj = getProject(req); if (proj) headers["OpenAI-Project"]      = proj;

      const model = (req.body?.model || process.env.HENRY_MODEL || "gpt-4o-mini").trim();

      const upstream = await fetch("https://api.openai.com/v1/chat/completions", {
        method: "POST",
        headers,
        body: JSON.stringify({ model, messages, temperature: 0.4 })
      });

      if (!upstream.ok){
        const detail = await upstream.text().catch(()=> "");
        return res.status(502).json({ ok:false, error:`upstream_${upstream.status}`, detail: detail.slice(0,800) });
      }
      const data = await upstream.json();
      const reply = data?.choices?.[0]?.message?.content || "(no content)";
      return res.json({ ok:true, model, reply });
    }

    // no key → local fallback
    return res.json({ ok:true, model:"local-fallback", reply: localPlan(lastUser(messages)) });
  }catch(e){
    return res.status(500).json({ ok:false, error:"server_error", detail: String(e?.message||e) });
  }
});

// ---- start ----
app.listen(PORT, ()=> console.log(`Henry API listening on http://127.0.0.1:${PORT}`));
