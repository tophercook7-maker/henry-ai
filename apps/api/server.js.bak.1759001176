import express from 'express';
import cors from 'cors';
import dotenv from 'dotenv';

dotenv.config();
const app = express();
app.use(cors());
app.use(express.json({ limit: '1mb' }));

app.get('/health', (_req, res) => res.json({ ok: true }));

/**
 * POST /chat
 * body: { message: string, system?: string, model?: string }
 * If OPENAI_API_KEY is set, calls OpenAI; otherwise echoes back.
 */
app.post('/chat', async (req, res) => {
  try {
    const { message = '', system = 'You are a helpful assistant.', model } = req.body || {};
    if (!message.trim()) return res.status(400).json({ error: 'message is required' });

    const OPENAI_API_KEY = process.env.OPENAI_API_KEY || '';
    if (!OPENAI_API_KEY) {
      return res.json({ reply: `echo: ${message}`, provider: 'echo' });
    }

    const usedModel = model || process.env.OPENAI_MODEL || 'gpt-4o-mini';
    const r = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${OPENAI_API_KEY}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        model: usedModel,
        messages: [
          { role: 'system', content: system },
          { role: 'user', content: message }
        ],
        temperature: 0.7
      })
    });

    if (!r.ok) {
      const text = await r.text().catch(() => '');
      return res.status(502).json({ error: 'upstream_error', detail: text.slice(0, 1000) });
    }

    const data = await r.json();
    const reply = data?.choices?.[0]?.message?.content ?? '';
    return res.json({ reply, provider: 'openai', model: usedModel });
  } catch (err) {
    console.error('POST /chat error', err);
    return res.status(500).json({ error: 'server_error' });
  }
});

const PORT = process.env.PORT || 3000;
app.listen(PORT, () => console.log(`API listening on :${PORT}`));
