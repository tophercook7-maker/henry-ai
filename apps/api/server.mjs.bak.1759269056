import express from 'express';
import cors from 'cors';
import multer from 'multer';
import { fetch } from 'undici';

const PORT = Number(process.env.PORT || 3000);
const app = express();

app.use(cors());
app.use(express.json({ limit: '2mb' }));
app.use(express.urlencoded({ extended: true, limit: '2mb' }));

// ---- basic health ----
app.get('/health', (_req, res) => res.json({ ok:true, service:'henry-api', ts:Date.now() }));
app.get('/ping',   (_req, res) => res.json({ ok:true }));

// ---- compatibility endpoints (prevent frontend 404s) ----
app.get('/index',  (_req, res) => res.json({ ok:true, msg:'index ok' }));
app.get('/key-status', (req, res) => {
  const auth = (req.get('x-api-key') || req.get('authorization') || '').trim();
  const key = auth.replace(/^Bearer\s+/i,'');
  res.json({ ok:true, hasKey: !!key, model: (req.get('x-model')||'gpt-4o-mini') });
});

// ---- uploads ----
const upload = multer({ dest: 'uploads/' });
app.post('/upload', upload.single('file'), (req, res) => {
  if(!req.file) return res.status(400).json({ ok:false, error:'no file' });
  res.json({
    ok:true,
    file:{
      originalName: req.file.originalname,
      savedName: req.file.filename,
      size: req.file.size,
      mime: req.file.mimetype,
      url: `/uploads/${req.file.filename}`
    }
  });
});
app.use('/uploads', express.static('uploads'));

// ---- chat (OpenAI if key, otherwise safe local reply) ----
app.post('/chat', async (req, res) => {
  try{
    const { messages = [] } = req.body || {};
    const auth = (req.get('x-api-key') || req.get('authorization') || '').trim();
    const key = auth.replace(/^Bearer\s+/i,'');
    const model = (req.get('x-model') || 'gpt-4o-mini').trim();

    if(!key){
      const last = (Array.isArray(messages) && messages[messages.length-1]?.content) || '';
      return res.json({
        ok:true,
        model:'local-fallback',
        reply:`Henry: I got “${String(last).slice(0,200)}”. Want steps, a summary, or next actions?`
      });
    }

    const r = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: { 'Authorization': `Bearer ${key}`, 'Content-Type':'application/json' },
      body: JSON.stringify({ model, messages: Array.isArray(messages)?messages:[], temperature: 0.7 })
    });

    if(!r.ok){
      const body = await r.text().catch(()=> '');
      return res.status(502).json({ ok:false, error:`OpenAI ${r.status}`, body: body.slice(0,500) });
    }

    const data = await r.json();
    const reply = data?.choices?.[0]?.message?.content || '(no reply)';
    res.json({ ok:true, model, reply });
  }catch(e){
    res.status(500).json({ ok:false, error:String(e?.message || e) });
  }
});

// ---- browse (safe; won’t crash boot) ----
import { route as browseRoute } from './routes/browse.mjs';
browseRoute(app);

// ---- start ----
app.listen(PORT, '127.0.0.1', () => {
  console.log(`Henry API listening on http://127.0.0.1:${PORT}`);
});
